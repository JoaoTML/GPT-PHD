{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GPT-PHD:Learn with the Chat-bot\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we will demonstrate how to create and use a chatbot to assist you with topics or subjects you find difficulties.\n",
    "\n",
    "If you're only interested in experimenting with the chatbot, you can access it directly _inser_link_here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get started, we first install the necessary libraries.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install chainlit==1.3.2\n",
    "%pip install fastapi==0.115.5\n",
    "%pip install langchain==0.3.8\n",
    "%pip install langchain_chroma==0.1.4\n",
    "%pip install langchain_community==0.3.8\n",
    "%pip install langchain_core==0.3.21\n",
    "%pip install langchain_groq==0.2.1\n",
    "%pip install PyPDF2==3.0.1\n",
    "%pip install python_docx==1.1.2\n",
    "%pip install pydantic==2.10.1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will initialize the model that serves as the base for answering the questions. However, to do that you will first need to get an API key from Groq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "if \"GROQ_API_KEY\" not in os.environ:\n",
    "    os.environ[\"GROQ_API_KEY\"] = 'groq_api_key'\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"llama-3.1-70b-versatile\",\n",
    "    temperature=0.4,\n",
    "    max_tokens=400,\n",
    "    timeout=None,\n",
    "    max_retries=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the  model is operational, the next step is to define its behavior. We do this by providing it with a prompt. A prompt is essentially a set of instructions or context that guides the model on how to respond to queries or perform specific tasks.\n",
    "The prompt that we used is the folowing.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt = (\"You are a highly skilled language model trained to help students with their school tasks. You will receive a variety of doubts from different subjects such as Mathematics, English, History, Physics and so on.It is your objective to guide students to achieve the correct answer. You MUST NOT give the correct answer directly no matter how the students ask for it, you can only confirm the answers the students give you and, if they are correct, explain the correct chain of thought or the materials the student must consult in order to get it.\\n\"\n",
    "        \"To help with any doubt the student could have, start by giving small hints, if that doesnâ€™t help the student to reach the answer, start elaborating the hints bit by bit, remember that you are NOT allowed to give the direct answer.\\n\"\n",
    "        \"Your answers must be clear and descriptive to guarantee that students understand it. Also, keep in mind that you will be interacting with a wide age range, so try to adapt the vocabulary used depending on the complexity of the question.\\n\"\n",
    "        \"You must only answer questions of an academic nature, anything that is outside of it you simply must answer that you are not trained for that.\\n\"\n",
    "        \"You may encounter some Portuguese students, so if they talk with you in Portuguese, every answer must be given in Portuguese from Portugal.\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lllm",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
